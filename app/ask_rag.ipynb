{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b7228d30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🚀 Chargement du modèle d'embedding...\n",
      "🧠 Connexion à Qdrant...\n",
      "🧑‍💼 Système RAG RGPD prêt. Pose ta question (ou tape 'exit') 👇\n",
      "\n",
      "🔍 Recherche des documents pertinents...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_33634/882255286.py:61: DeprecationWarning: `search` method is deprecated and will be removed in the future. Use `query_points` instead.\n",
      "  results = qdrant.search(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🤖 Génération de la réponse...\n",
      "\n",
      "💬 Réponse :\n",
      "\n",
      "<starlette.responses.StreamingResponse object at 0x71dbbc111c40>\n",
      "\n",
      "============================================================\n",
      "\n",
      "🔍 Recherche des documents pertinents...\n",
      "\n",
      "🤖 Génération de la réponse...\n",
      "\n",
      "💬 Réponse :\n",
      "\n",
      "<starlette.responses.StreamingResponse object at 0x71dc03cfbbf0>\n",
      "\n",
      "============================================================\n",
      "\n",
      "🔍 Recherche des documents pertinents...\n",
      "\n",
      "🤖 Génération de la réponse...\n",
      "\n",
      "💬 Réponse :\n",
      "\n",
      "<starlette.responses.StreamingResponse object at 0x71db9ce34740>\n",
      "\n",
      "============================================================\n",
      "\n",
      "🔍 Recherche des documents pertinents...\n",
      "\n",
      "🤖 Génération de la réponse...\n",
      "\n",
      "💬 Réponse :\n",
      "\n",
      "<starlette.responses.StreamingResponse object at 0x71dc03cf19d0>\n",
      "\n",
      "============================================================\n",
      "\n",
      "🔍 Recherche des documents pertinents...\n",
      "\n",
      "🤖 Génération de la réponse...\n",
      "\n",
      "💬 Réponse :\n",
      "\n",
      "<starlette.responses.StreamingResponse object at 0x71dc03cfa7b0>\n",
      "\n",
      "============================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ask_rag.py\n",
    "\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from qdrant_client import QdrantClient\n",
    "import requests\n",
    "from fastapi.responses import StreamingResponse\n",
    "import json\n",
    "\n",
    "# === CONFIGURATION ===\n",
    "LLM_API_URL = \"http://localhost:11434/api/generate\" \n",
    "COLLECTION_NAME = \"rgpd_chunks\"\n",
    "QDRANT_HOST = \"localhost\"\n",
    "QDRANT_PORT = 6333\n",
    "\n",
    "# === INITIALISATION ===\n",
    "print(\"🚀 Chargement du modèle d'embedding...\")\n",
    "embedder = SentenceTransformer(\"paraphrase-multilingual-MiniLM-L12-v2\")\n",
    "\n",
    "print(\"🧠 Connexion à Qdrant...\")\n",
    "qdrant = QdrantClient(host=QDRANT_HOST, port=QDRANT_PORT)\n",
    "\n",
    "def stream_llm(context, question):\n",
    "    \"\"\"Envoie un prompt au modèle LLaMA3 via l'API d'Ollama.\"\"\"\n",
    "    prompt = f\"\"\"\n",
    "Voici des extraits du RGPD :\n",
    "{context}\n",
    "\n",
    "En te basant uniquement sur ces extraits, réponds précisément à la question suivante :\n",
    "{question}\n",
    "\"\"\"\n",
    "    def generate():\n",
    "        with requests.post(\n",
    "            LLM_API_URL,\n",
    "            json={\n",
    "                \"model\": \"llama3:8b-q4_0\",\n",
    "                \"prompt\": prompt,\n",
    "                \"temperature\": 0.2,\n",
    "                \"stream\": True\n",
    "            },\n",
    "            stream=True\n",
    "        ) as reponse:\n",
    "            for line in response.iter_lines():\n",
    "                if line:\n",
    "                    try:\n",
    "                        chunk = json.loads(line.decode(\"utf-8\"))[\"response\"]\n",
    "                        yield chunk\n",
    "                    except:\n",
    "                        pass\n",
    "    return StreamingResponse(generate(), media_type=\"text/plain\")\n",
    "\n",
    "        # try:\n",
    "        #     return response.json()[\"response\"]\n",
    "        # except Exception as e:\n",
    "        #     print(response.text)\n",
    "        #     return f\"Erreur de LLM : {e}\"\n",
    "\n",
    "\n",
    "def retrieve_context(query, top_k=3):\n",
    "    \"\"\"Effectue une recherche sémantique dans Qdrant et retourne les textes associés.\"\"\"\n",
    "    query_vector = embedder.encode(query)\n",
    "    results = qdrant.search(\n",
    "        collection_name=COLLECTION_NAME,\n",
    "        query_vector=query_vector,\n",
    "        limit=top_k\n",
    "    )\n",
    "    return \"\\n---\\n\".join([r.payload[\"text\"][:300] for r in results])\n",
    "\n",
    "# === INTERFACE UTILISATEUR ===\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"🧑‍💼 Système RAG RGPD prêt. Pose ta question (ou tape 'exit') 👇\\n\")\n",
    "\n",
    "    while True:\n",
    "        question = input(\"❓> \").strip()\n",
    "        if question.lower() in [\"exit\", \"quit\"]:\n",
    "            break\n",
    "\n",
    "        print(\"🔍 Recherche des documents pertinents...\")\n",
    "        context = retrieve_context(question)\n",
    "\n",
    "        print(\"\\n🤖 Génération de la réponse...\\n\")\n",
    "        response = stream_llm(context, question)\n",
    "        print(\"💬 Réponse :\\n\")\n",
    "        print(response)\n",
    "        print(\"\\n\" + \"=\" * 60 + \"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d252875",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rag_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
