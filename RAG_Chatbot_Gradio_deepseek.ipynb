{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BzFYwiBDxuQG"
   },
   "source": [
    "#Mastering RAG Chatbots with DeepSeek: From Implementation to Deployment\n",
    "\n",
    "Key Modifications from OpenAI Version:\n",
    "Replace OpenAI API calls with DeepSeek API\n",
    "Use DeepSeek's embedding and chat completion models\n",
    "Add error handling specific to DeepSeek API\n",
    "\n",
    "- Create a new Jupyter notebook named RAG_Chatbot_Gradio_Tutorial_DeepSeek.ipynb\n",
    "- Copy the code structure I've outlined\n",
    "- Replace placeholders like YOUR_DEEPSEEK_API_KEY with actual credentials\n",
    "- Adjust import statements and method calls based on the actual DeepSeek API library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 5895,
     "status": "ok",
     "timestamp": 1744930014151,
     "user": {
      "displayName": "Abdoul Aziz TIENDREBEOGO",
      "userId": "02900456517849310698"
     },
     "user_tz": -120
    },
    "id": "dha1X_Tyxz2v"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/abdoul/rag_lawyer/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# 1. Environment Setup\n",
    "# !pip install openai requests beautifulsoup4 PyPDF2 numpy gradio -q\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import PyPDF2\n",
    "# from deepseek import DeepSeek  # Hypothetical import, adjust based on actual library\n",
    "from openai import OpenAI\n",
    "import gradio as gr\n",
    "\n",
    "# Set DeepSeek API Key\n",
    "deepseek_client =OpenAI(api_key=\"sk-005d9d3de8d946ecbf9721293c44d6be\", base_url=\"https://api.deepseek.com\")\n",
    "\n",
    "\n",
    "# 2. Content Extraction (Same as OpenAI version)\n",
    "def scrape_website(url):\n",
    "    # ... (unchanged)\n",
    "    \"\"\"Scrape text content from a website\"\"\"\n",
    "    try:\n",
    "        response = requests.get(url)\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "        return ' '.join(soup.stripped_strings)\n",
    "    except Exception as e:\n",
    "        return f\"Error scraping website: {str(e)}\"\n",
    "\n",
    "def extract_pdf_content(pdf_path):\n",
    "    \"\"\"Extract text from a PDF file\"\"\"\n",
    "    try:\n",
    "        with open(pdf_path, 'rb') as file:\n",
    "            reader = PyPDF2.PdfReader(file)\n",
    "            # Corrected indentation for the return statement\n",
    "            return ' '.join(page.extract_text() for page in reader.pages)\n",
    "    except Exception as e:\n",
    "        return f\"Error processing PDF: {str(e)}\"\n",
    "    \n",
    "def split_into_chunks(text, chunk_size=500):\n",
    "    \"\"\"Split text into manageable chunks\"\"\"\n",
    "    words = text.split()\n",
    "    return [' '.join(words[i:i+chunk_size]) for i in range(0, len(words), chunk_size)]\n",
    "\n",
    "# 3. Text Processing and Embedding\n",
    "def generate_embeddings(text):\n",
    "    \"\"\"Generate embeddings using DeepSeek\"\"\"\n",
    "    response = deepseek_client.embeddings.create(\n",
    "        model=\"text-embedding-v1\",  # Adjust model name as per DeepSeek's offering\n",
    "        input=text\n",
    "    )\n",
    "    return response.embeddings[0]\n",
    "\n",
    "def cosine_similarity(vec1, vec2):\n",
    "    \"\"\"Compute cosine similarity between two vectors\"\"\"\n",
    "    return np.dot(vec1, vec2) / (np.linalg.norm(vec1) * np.linalg.norm(vec2))\n",
    "\n",
    "# 4. RAG Chatbot Core Implementation\n",
    "class RAGChatbot:\n",
    "    def ask(self, query):\n",
    "        relevant_chunk = self.find_relevant_chunk(query)\n",
    "\n",
    "        response = deepseek_client.chat.completions.create(\n",
    "            model=\"deepseek-reasoner\",  # Adjust model name\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": \"You are a helpful assistant using context to answer questions.\"},\n",
    "                {\"role\": \"user\", \"content\": f\"Context: {relevant_chunk}\\n\\nQuery: {query}\"}\n",
    "            ],\n",
    "            max_tokens=200\n",
    "        )\n",
    "        return response.choices[0].message.content\n",
    "\n",
    "\n",
    "    def load_from_url(self, url):\n",
    "        \"\"\"Load content from a website\"\"\"\n",
    "        content = scrape_website(url)\n",
    "        self._process_content(content)\n",
    "\n",
    "    def load_from_pdf(self, pdf_path):\n",
    "        \"\"\"Load content from a PDF\"\"\"\n",
    "        content = extract_pdf_content(pdf_path)\n",
    "        self._process_content(content)\n",
    "\n",
    "    def _process_content(self, content):\n",
    "        \"\"\"Process content into chunks and generate embeddings\"\"\"\n",
    "        chunks = split_into_chunks(content)\n",
    "        self.chunks_with_embeddings = [\n",
    "            {\"content\": chunk, \"embedding\": generate_embeddings(chunk)}\n",
    "            for chunk in chunks\n",
    "        ]\n",
    "\n",
    "    def find_relevant_chunk(self, query):\n",
    "        \"\"\"Find most relevant text chunk for a query\"\"\"\n",
    "        query_embedding = generate_embeddings(query)\n",
    "        similarities = [\n",
    "            (chunk[\"content\"], cosine_similarity(query_embedding, chunk[\"embedding\"]))\n",
    "            for chunk in self.chunks_with_embeddings\n",
    "        ]\n",
    "        return max(similarities, key=lambda x: x[1])[0]\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WOHn2-v-pRaz"
   },
   "source": [
    "# Gradio Web Interface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "kUNYzV_JpRa0"
   },
   "outputs": [],
   "source": [
    "# --- ipython-input-7-7774a7eacb87 ---\n",
    "class RAGChatbotInterface:\n",
    "    def __init__(self):\n",
    "        self.chatbot = RAGChatbot()\n",
    "        self.chat_history = []\n",
    "\n",
    "    def process_file(self, file):\n",
    "        \"\"\"Process uploaded PDF file\"\"\"\n",
    "        try:\n",
    "            self.chatbot.load_from_pdf(file.name)\n",
    "            return \"PDF successfully loaded! You can now ask questions.\"\n",
    "        except Exception as e:\n",
    "            return f\"Error processing PDF: {str(e)}\"\n",
    "\n",
    "    def process_url(self, url):\n",
    "        \"\"\"Process website URL\"\"\"\n",
    "        try:\n",
    "            self.chatbot.load_from_url(url)\n",
    "            return \"Website content successfully loaded! You can now ask questions.\"\n",
    "        except Exception as e:\n",
    "            return f\"Error processing URL: {str(e)}\"\n",
    "\n",
    "    def chat(self, message, history):\n",
    "        \"\"\"Process chat message and update history\"\"\"\n",
    "        try:\n",
    "            response = self.chatbot.ask(message)\n",
    "            history.append((message, response))\n",
    "            return response, history\n",
    "        except Exception as e:\n",
    "            error_message = f\"Error generating response: {str(e)}\"\n",
    "            history.append((message, error_message))\n",
    "            return error_message, history\n",
    "\n",
    "    def launch_interface(self, share=True):\n",
    "        \"\"\"Create and launch Gradio interface\"\"\"\n",
    "        with gr.Blocks(title=\"RAG Chatbot\") as interface:\n",
    "            gr.Markdown(\"# ðŸ“š RAG Chatbot: Learn from Any Document\")\n",
    "\n",
    "            with gr.Tab(\"PDF Input\"):\n",
    "                # Change 'type' to 'filepath' to get the file path\n",
    "                pdf_upload = gr.File(label=\"Upload PDF\", type=\"filepath\", file_types=[\".pdf\"])\n",
    "                pdf_status = gr.Textbox(label=\"PDF Status\", interactive=False)\n",
    "                pdf_upload.upload(fn=self.process_file, inputs=[pdf_upload], outputs=[pdf_status])\n",
    "\n",
    "            with gr.Tab(\"URL Input\"):\n",
    "                url_input = gr.Textbox(label=\"Enter Website URL\", placeholder=\"https://example.com\")\n",
    "                url_status = gr.Textbox(label=\"URL Status\", interactive=False)\n",
    "                url_button = gr.Button(\"Load Content\")\n",
    "                url_button.click(fn=self.process_url, inputs=[url_input], outputs=[url_status])\n",
    "\n",
    "            chatbot = gr.Chatbot(label=\"Chat with Your Document\", height=400)\n",
    "            msg = gr.Textbox(label=\"Your Question\", placeholder=\"Ask a question about the document...\")\n",
    "            clear = gr.Button(\"Clear Chat\")\n",
    "\n",
    "            msg.submit(fn=self.chat, inputs=[msg, chatbot], outputs=[msg, chatbot])\n",
    "            clear.click(lambda: None, None, chatbot, queue=False)\n",
    "\n",
    "        interface.launch(share=share)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a9NvffjppRa0"
   },
   "source": [
    "## 6. Launching the RAG Chatbot Interface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 648
    },
    "executionInfo": {
     "elapsed": 1038,
     "status": "ok",
     "timestamp": 1739289533383,
     "user": {
      "displayName": "Habiboulaye AMADOU B.",
      "userId": "00224232757473049450"
     },
     "user_tz": -60
    },
    "id": "eG3T2eoOpRa1",
    "outputId": "e0b81f0a-d2c8-4517-bc9b-912e1498352a"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_19798/4037565904.py:51: UserWarning: You have not specified a value for the `type` parameter. Defaulting to the 'tuples' format for chatbot messages, but this is deprecated and will be removed in a future version of Gradio. Please set type='messages' instead, which uses openai-style dictionaries with 'role' and 'content' keys.\n",
      "  chatbot = gr.Chatbot(label=\"Chat with Your Document\", height=400)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7860\n",
      "\n",
      "Could not create share link. Please check your internet connection or our status page: https://status.gradio.app.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/04/23 23:25:27 [W] [service.go:132] login to server failed: dial tcp 44.237.78.176:7000: i/o timeout\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create and launch the interface\n",
    "rag_interface = RAGChatbotInterface()\n",
    "rag_interface.launch_interface(share=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XccK1E4ApRa1"
   },
   "source": [
    "## Learning Outcomes\n",
    "\n",
    "By completing this tutorial, you will have learned:\n",
    "\n",
    "1. **Content Extraction Techniques**\n",
    "   - Web scraping with BeautifulSoup\n",
    "   - PDF text extraction\n",
    "\n",
    "2. **Text Processing**\n",
    "   - Text chunking strategies\n",
    "   - Semantic embedding generation\n",
    "\n",
    "3. **RAG Architecture**\n",
    "   - Context retrieval\n",
    "   - Similarity-based chunk selection\n",
    "   - Prompt engineering\n",
    "\n",
    "4. **Web Interface Development**\n",
    "   - Creating interactive UIs with Gradio\n",
    "   - Handling file and URL inputs\n",
    "   - Managing chat interactions\n",
    "\n",
    "## Challenges and Extensions\n",
    "\n",
    "1. Implement multi-document support\n",
    "2. Add more sophisticated embedding techniques\n",
    "3. Improve error handling and input validation\n",
    "4. Create a more advanced prompt engineering strategy\n",
    "5. Implement conversation memory\n",
    "\n",
    "## Ethical Considerations\n",
    "\n",
    "- Always respect copyright and terms of service\n",
    "- Be mindful of privacy when processing documents\n",
    "- Use AI responsibly and ethically"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
